## 2. ELT with Apache Spark


Extract data from a single file and from a directory of files.

Identify the prefix included after the FROM keyword as the data type.

Create a view, a temporary view, and a CTE as a reference to a file.

Identify that tables from external sources are not Delta Lake tables.

Create a table from a JDBC connection and from an external CSV file.

Identify how the count_if function and the count where x is null can be used

Identify how the count(row) skips NULL values.

Deduplicate rows from an existing Delta Lake table.

Create a new table from an existing table while removing duplicate rows.

Deduplicate a row based on specific columns.

Validate that the primary key is unique across all rows.

Validate that a field is associated with just one unique value in another field.

Validate that a value is not present in a specific field.

Cast a column to a timestamp.

Extract calendar data from a timestamp.

Extract a specific pattern from an existing string column.

Utilize the dot syntax to extract nested data fields.

Identify the benefits of using array functions.

Parse JSON strings into structs.

Identify which result will be returned based on a join query.

Identify a scenario to use the explode function versus the flatten function

Identify the PIVOT clause as a way to convert data from wide format to a long format.

Define a SQL UDF.

Identify the location of a function.

Describe the security model for sharing SQL UDFs.

Use CASE/WHEN in SQL code.

Leverage CASE/WHEN for custom control flow.